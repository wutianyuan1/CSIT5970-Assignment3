{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "ba17d3ac-aa17-4d8f-b265-bb1a3d81964e",
          "showTitle": false,
          "title": ""
        },
        "id": "aOWn0xhxMKMa"
      },
      "source": [
        "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
        "\n",
        "# **Warmup Notebook: Testing Environment**\n",
        "\n",
        "*Note: This notebook is merely a warmup exercise and not subject to grading.*\n",
        "\n",
        "This notebook will show you how to install the test libraries, test basic notebook functionality, and export a notebook for submitting. To move through the notebook, just run each of the cells. You will not need to solve any problems to complete this lab. You can run a cell by pressing \"shift-enter\", which will compute the current cell and advance to the next cell, or by clicking in a cell and pressing \"control-enter\", which will compute the current cell and remain in that cell.\n",
        "\n",
        "**Within this notebook we will cover:**\n",
        "\n",
        "- *Part 1*: Testing Spark Functionality\n",
        "- *Part 2*: Checking Test Helper\n",
        "- *Part 3*: Checking Matplotlib Support\n",
        "- *Part 4*: Checking KaTeX Support\n",
        "- *Part 5*: Exporting Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "4a49323a-41c1-49b7-82e0-a92fdb1b39f6",
          "showTitle": false,
          "title": ""
        },
        "id": "rREBe4xlMKMf"
      },
      "source": [
        "#### Prelude\n",
        "\n",
        "**(1a) Importing Test Helper**\n",
        "\n",
        "The class helper library \"test_helper\" is published in the [GitHub repository](https://github.com/hpec/test_helper) as [test_helper](https://pypi.org/project/test_helper/) package. Here we can manually import the \"Test\" class for use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a287e4f6-da35-46b6-a779-f393ec544b81",
          "showTitle": false,
          "title": ""
        },
        "id": "bLT4VtWiMKMg"
      },
      "outputs": [],
      "source": [
        "# initialize the Test class\n",
        "import hashlib\n",
        "\n",
        "class TestFailure(Exception):\n",
        "    pass\n",
        "class PrivateTestFailure(Exception):\n",
        "    pass\n",
        "\n",
        "class Test(object):\n",
        "    passed = 0\n",
        "    numTests = 0\n",
        "    failFast = False\n",
        "    private = False\n",
        "\n",
        "    @classmethod\n",
        "    def setFailFast(cls):\n",
        "        cls.failFast = True\n",
        "\n",
        "    @classmethod\n",
        "    def setPrivateMode(cls):\n",
        "        cls.private = True\n",
        "\n",
        "    @classmethod\n",
        "    def assertTrue(cls, result, msg=\"\"):\n",
        "        cls.numTests += 1\n",
        "        if result == True:\n",
        "            cls.passed += 1\n",
        "            print(\"1 test passed.\")\n",
        "        else:\n",
        "            print(\"1 test failed. \" + msg)\n",
        "            if cls.failFast:\n",
        "                if cls.private:\n",
        "                    raise PrivateTestFailure(msg)\n",
        "                else:\n",
        "                    raise TestFailure(msg)\n",
        "\n",
        "    @classmethod\n",
        "    def assertEquals(cls, var, val, msg=\"\"):\n",
        "        cls.assertTrue(var == val, msg)\n",
        "\n",
        "    @classmethod\n",
        "    def assertEqualsHashed(cls, var, hashed_val, msg=\"\"):\n",
        "        cls.assertEquals(cls._hash(var), hashed_val, msg)\n",
        "\n",
        "    @classmethod\n",
        "    def printStats(cls):\n",
        "        print(\"{0} / {1} test(s) passed.\".format(cls.passed, cls.numTests))\n",
        "\n",
        "    @classmethod\n",
        "    def _hash(cls, x):\n",
        "        return hashlib.sha1(str(x).encode('utf-8')).hexdigest()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "ebf0b1f3-9fac-4b1e-9eb7-46c90f5615df",
          "showTitle": false,
          "title": ""
        },
        "id": "SBAoYxydMKMi"
      },
      "source": [
        "**(1b) Uploading Text File**\n",
        "\n",
        "Now we upload a text file `shakespere.txt` to Colab which will be used in next part.\n",
        "\n",
        "![upload_file](https://raw.githubusercontent.com/HKUST-COMP4651-24S/assets/main/assignment-3/upload-file.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsbGiEF7b-Y9"
      },
      "source": [
        "**(1c) Installing PySpark**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLK3CIR8N0o-"
      },
      "outputs": [],
      "source": [
        "! pip install pyspark==3.5.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "120f31a0-cabb-4f2a-a282-2bcb7c520534",
          "showTitle": false,
          "title": ""
        },
        "id": "qdNtGLMTMKMi"
      },
      "source": [
        "#### **Part 1: Testing Spark functionality**\n",
        "\n",
        "**(1a) Common Operators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "30d22616-04ac-4cec-9041-977d21653d1b",
          "showTitle": false,
          "title": ""
        },
        "id": "tpYz4rZrMKMj"
      },
      "outputs": [],
      "source": [
        "# import pyspark and initiate a SparkContext\n",
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "conf = SparkConf().setAppName('Spark Programming')\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "# check whether Spark is working properly\n",
        "largeRange = sc.parallelize(range(100000))\n",
        "reduceTest = largeRange.reduce(lambda a, b: a + b)\n",
        "filterReduceTest = largeRange.filter(lambda x: x % 7 == 0).sum()\n",
        "\n",
        "print(reduceTest)\n",
        "print(filterReduceTest)\n",
        "\n",
        "# AssertionError will be raised if Spark is malfunctioning\n",
        "assert reduceTest == 4999950000\n",
        "assert filterReduceTest == 714264285"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "5ac93956-7b66-4930-8768-6b668023e741",
          "showTitle": false,
          "title": ""
        },
        "id": "kuoTZNOLMKMj"
      },
      "source": [
        "**(1b) Loading Text File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "e383fdc5-a161-49ad-9a60-9059810c5e67",
          "showTitle": false,
          "title": ""
        },
        "id": "6U81UlHgMKMj"
      },
      "outputs": [],
      "source": [
        "# load text file with sc.textFile\n",
        "import os.path\n",
        "filePath = 'shakespere.txt'\n",
        "\n",
        "rawData = sc.textFile(filePath)\n",
        "shakespeareCount = rawData.count()\n",
        "\n",
        "print(shakespeareCount)\n",
        "\n",
        "assert shakespeareCount == 149689"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "f8984dd8-b3f7-4276-ba9b-da5723d3f8b0",
          "showTitle": false,
          "title": ""
        },
        "id": "PF_fw6ZYMKMk"
      },
      "source": [
        "#### ** Part 2: Checking Test Helper **\n",
        "\n",
        "** (2a) Hash Comparison **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "85b73ae3-5709-4a55-8622-7ec8b83fb2ce",
          "showTitle": false,
          "title": ""
        },
        "id": "U-ZLB76YMKMk"
      },
      "outputs": [],
      "source": [
        "# Check our testing library/package\n",
        "# This should print '1 test passed.' on two lines\n",
        "twelve = 12\n",
        "Test.assertEquals(twelve, 12, 'twelve should equal 12')\n",
        "Test.assertEqualsHashed(twelve, '7b52009b64fd0a2a49e6d8a939753077792b0554',\n",
        "                        'twelve, once hashed, should equal the hashed value of 12')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "cc58a017-4b22-4ec0-b1ab-8e7b72408e58",
          "showTitle": false,
          "title": ""
        },
        "id": "25oqk5cHMKMk"
      },
      "source": [
        "**(2b) List Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "03461e90-a4bf-4f78-852a-bb1dd5a51613",
          "showTitle": false,
          "title": ""
        },
        "id": "_K38eFN3MKMl"
      },
      "outputs": [],
      "source": [
        "# This should print '1 test passed.'\n",
        "unsortedList = [(5, 'b'), (5, 'a'), (4, 'c'), (3, 'a')]\n",
        "Test.assertEquals(sorted(unsortedList), [(3, 'a'), (4, 'c'), (5, 'a'), (5, 'b')],\n",
        "                  'unsortedList does not sort properly')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "bc1551df-97d6-4132-a750-4ec6b3f58b17",
          "showTitle": false,
          "title": ""
        },
        "id": "JmZ0LtxQMKMl"
      },
      "source": [
        "#### ** Part 3: Checking Matplotlib Support **\n",
        "\n",
        "** (3a) Our first plot **\n",
        "\n",
        "After executing the code cell below, you should see a plot with 50 blue circles.  The circles should start at the bottom left and end at the top right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "aba9ce67-e966-47d9-a271-bacd8bd555e9",
          "showTitle": false,
          "title": ""
        },
        "id": "JPKrkmG_MKMl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from math import log\n",
        "\n",
        "# function for generating plot layout\n",
        "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999', gridWidth=1.0):\n",
        "    plt.close()\n",
        "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
        "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
        "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
        "        axis.set_ticks_position('none')\n",
        "        axis.set_ticks(ticks)\n",
        "        axis.label.set_color('#999999')\n",
        "        if hideLabels: axis.set_ticklabels([])\n",
        "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
        "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
        "    return fig, ax\n",
        "\n",
        "# generate layout and plot data\n",
        "x = range(1, 50)\n",
        "y = [log(x1 ** 2) for x1 in x]\n",
        "fig, ax = preparePlot(range(5, 60, 10), range(0, 12, 1))\n",
        "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
        "ax.set_xlabel(r'$range(1, 50)$'), ax.set_ylabel(r'$\\log_e(x^2)$')\n",
        "\n",
        "# call display() to show the figure\n",
        "display(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "0a1420a2-04b3-442e-90fd-a1cdd7e8259e",
          "showTitle": false,
          "title": ""
        },
        "id": "KUYCaHBKMKMl"
      },
      "source": [
        "#### ** Part 4: Checking KaTeX Support **\n",
        "\n",
        "The notebooks render LaTeX formulae with [KaTeX](https://katex.org/). [Here](https://katex.org/docs/supported.html) is a list of all supported symbols and macros.\n",
        "\n",
        "**Tip**: The common newline `\\\\` in LaTeX is not allowed here, so you have to use `\\cr` instead.\n",
        "\n",
        "** (4a) Gradient descent formula **\n",
        "\n",
        "You should see a formula on the line below this one: $$ \\small \\mathbf{w}_{i+1} = \\mathbf{w}_i - \\alpha_i \\sum_j (\\mathbf{w}_i^\\top\\mathbf{x}_j  - y_j) \\mathbf{x}_j \\,.$$\n",
        "\n",
        "This formula is included inline with the text and is \\\\( \\small (\\mathbf{w}^\\top \\mathbf{x} - y) \\mathbf{x} \\\\).\n",
        "\n",
        "** (4b) Log loss formula **\n",
        "\n",
        "This formula shows log loss for single point. Log loss is defined as:\n",
        "$$\n",
        "\\small\n",
        "loss(p, y) = \\begin{cases}\n",
        "   -\\log(p)   & \\text{if } y = 1 \\cr\n",
        "   -\\log(1-p) & \\text{if } y = 0\n",
        "\\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "0ff86b3d-9347-49d7-a527-805328c86eab",
          "showTitle": false,
          "title": ""
        },
        "id": "6bdOlSfkMKMm"
      },
      "source": [
        "#### ** Part 5: Exporting Notebook**\n",
        "\n",
        "Export and download the notebook from Colab, click on \"File\", then select \"Download\" and \"Download .py\". This will export your notebook as a `.py` file to your computer.\n",
        "\n",
        "<br/>\n",
        "\n",
        "![export_notebook](https://raw.githubusercontent.com/HKUST-COMP4651-24S/assets/main/assignment-3/export-notebook.png)\n",
        "\n",
        "<br/>\n",
        "\n",
        "When you've done coding, you can add the exported `.py` file to the GitHub repository, commit, and push it to GitHub for grading."
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "warmup",
      "notebookOrigID": 4176429342212458,
      "widgets": {}
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": "2"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "name": "warmup",
    "notebookId": 2014053316510764
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
